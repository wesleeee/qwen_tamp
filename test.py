import torch
import numpy as np
from typing import List
import torch.nn.functional as F

# ğŸ‘‡è¯·å°†ä½ è‡ªå·±çš„ fast å‡½æ•°ç²˜è´´è¿›æ¥
from my_prune_on_gpu import get_activate_tokens_fast  # æ›¿æ¢ä¸ºä½ çš„å®é™…æ¨¡å—è·¯å¾„

def generate_test_data(L=100, D=256, seed=0):
    torch.manual_seed(seed)
    np.random.seed(seed)

    tokens = torch.randn(L, D)                # éšæœº token å‘é‡
    attention = torch.rand(L, 1)              # å•åˆ—æ³¨æ„åŠ›å€¼
    return [attention], [tokens]

def test_get_activate_tokens_fast():
    attention_values, token_list = generate_test_data(L=100, D=256)
    num_neighbors = 3
    sparsity_dict = {0: 5}

    print("ğŸ” Running get_activate_tokens_fast on 100 tokens...")

    results = get_activate_tokens_fast(
        attention_values,
        token_list,
        num_neighbors,
        sparsity_dict,
        epsilon=-0.1  # å¯è°ƒ
    )

    for block, val in results.items():
        shape = val.shape  # [1, K, D]
        num_selected = shape[1]
        print(f"âœ… Block {block}: selected {num_selected} tokens out of 100.")
        if num_selected <= 12:
            print("âš ï¸  Warning: Selected too few tokens â€” possible early exit!")

if __name__ == "__main__":
    test_get_activate_tokens_fast()
